{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fde5adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\dulne\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dulne\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#Installing the open ai package for fine tuning\n",
    "!pip install -U openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fc8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the openai module\n",
    "from openai import OpenAI\n",
    "#Give our API key AND CREATE AN INSTANCE  \n",
    "client = OpenAI(api_key = \"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\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2af7c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='As a nutritionist, I would not recommend regular Coca-Cola for someone with diabetes. Regular Coca-Cola contains a high amount of sugar, which can cause spikes in blood sugar levels for people with diabetes. It is important for individuals with diabetes to monitor their carbohydrate intake and choose beverages that are lower in sugar.\\n\\nIf you are looking for a Coca-Cola alternative, you may consider trying diet or zero sugar versions of Coca-Cola that are sweetened with artificial sweeteners instead of sugar. However, it is still important to consume these options in moderation and be aware of any potential effects they may have on your blood sugar levels.\\n\\nOverall, it is best to prioritize water, unsweetened tea, or other low-sugar beverages as healthier options for managing diabetes and maintaining overall health. It is also recommended to consult with a healthcare provider or a registered dietitian for personalized nutrition advice tailored to your specific health needs.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model =\"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\":\"system\" , \"content\": \"You are going an AI  nutritionist, skilled in extracting relavant informationto a food product and giving personal recommendations for users.\"},\n",
    "        {\"role\":\"user\" , \"content\": \"i have diabetese, what are your thoughts on coca cola.\"},\n",
    "       \n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff442d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Role: Maliban cream cracker, User Description:...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Role: Maliban cream cracker, User Description:...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Role:  Maliban cream cracker, User Description...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Role: Maliban cream cracker, User Description:...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt      rate\n",
       "0  Role: Maliban cream cracker, User Description:...      good\n",
       "1  Role:  Maliban cream cracker, User Description...      good\n",
       "2  Role:  Maliban cream cracker, User Description...  moderate\n",
       "3  Role:  Maliban cream cracker, User Description...      good\n",
       "4  Role:  Maliban cream cracker, User Description...      good\n",
       "5  Role:  Maliban cream cracker, User Description...      good\n",
       "6  Role: Maliban cream cracker, User Description:...       bad\n",
       "7  Role:  Maliban cream cracker, User Description...  moderate\n",
       "8  Role:  Maliban cream cracker, User Description...  moderate\n",
       "9  Role: Maliban cream cracker, User Description:...  moderate"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing our dataset \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"healthquiz_data.csv\")\n",
    "\n",
    "#printing the first 10 rows to check if successful import\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f585f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test my accuracy later , im creating a new csv and adding the first 10 data to it\n",
    "# ml has training set , and testing set\n",
    "\n",
    "df_head = df.head(10)\n",
    "\n",
    "#SAVE THE NEW FILE AS A CSV FILE AND STORE THE 10 VALUES of our dataset\n",
    "df_head.to_csv(\"nutrimate_rating_test.csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be4baf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move the  data excluding the first 10  from original csv to a  test file, this is to test if the llm gives correct prediction when we give it \n",
    "#the existing data it hasnt seen yet\n",
    "\n",
    "df = df.iloc[10:]\n",
    "\n",
    "df.to_csv(\"healthquiz_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f29fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"Role:  Maliban cream cracker, User Description: As a college student, I'm eager to adopt healthier eating habits that support my academic success and overall well-being. I'm looking for budget-friendly meal ideas and snacks to keep me energized throughout the day.\"},\n",
       " {'role': 'assistant', 'content': '{\"rate\": \"good\"}'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting csv data to a format to be sent to openAi\n",
    "\n",
    "def convert_to_gpt35_format(dataset):\n",
    "    fine_tuning_data = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        #Drefining a template for our llm output to be formatted\n",
    "       #for each row we access the rating and pass it to gpt along with description\n",
    "        json_response = '{\"rate\": \"' + row['rate'] + '\"}'\n",
    "        \n",
    "        #             Row has promp and user, we pas the promt record in the context of user\n",
    "        \n",
    "        #                 Assistant should give the answer in the format as above as Json response\n",
    "        \n",
    "        fine_tuning_data.append({\n",
    "\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                {\"role\": \"assistant\", \"content\": json_response}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    return fine_tuning_data\n",
    "#Json response is teh response foramt our open AI model is going to give\n",
    "#store data in dataset variable\n",
    "dataset = pd.read_csv('healthquiz_data.csv')\n",
    "# Call the function passing our dataset\n",
    "converted_data = convert_to_gpt35_format(dataset)\n",
    "#print of what the 22 data looks like , this is the format openAI can read\n",
    "converted_data[0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37bcccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rate': 'good'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "# in massages array of objects we get the last dictionary and inside that dictionalry we access the content key\n",
    "# convert the string to json\n",
    "json.loads(converted_data[0]['messages'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c176b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#destructing 2 variables train data and validation data , 20% for validation data from dastset and rest goes to test data\n",
    "# Stratified splitting. Assuming 'Top Category' can be used for stratification\n",
    "train_data, val_data = train_test_split(\n",
    "    converted_data,\n",
    "    test_size=0.2,\n",
    "    stratify=dataset['rate'],\n",
    "    random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "#Here what we are doing  we convert our dataset  it to a trained set and validate data set\n",
    "#test size = 0.2 means from the data 20% is out to validation data the rest 80% is put train data array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d7525fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted data should be in json format not an array so we convert it with the folowing code\n",
    "#we split  the train and val data above code ans we pass them to create a json object with the function\n",
    "#previosly we created test and validation for our usecase, but this time we split the array pof objects containg our dataset rows and \n",
    "#give it to gpt for their triang and validation data\n",
    "\n",
    "def write_to_jsonl(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for entry in data:\n",
    "            json.dump(entry, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "\n",
    "training_file_name = \"train.jsonl\"\n",
    "validation_file_name = \"val.jsonl\"\n",
    "# OPen ai needs a trainign data file and a validation dayata file which we crfeated\n",
    "write_to_jsonl(train_data, training_file_name)\n",
    "write_to_jsonl(val_data, validation_file_name)\n",
    "\n",
    "#these traing and validation file is what we are gooing to pass to open AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a44599fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-IDCSB0tz8UE9Roa4DNZHIo8O\n",
      "Validation file id: file-mNku25Ynikh0nmkDsWhZO05r\n"
     ]
    }
   ],
   "source": [
    "#This step is given by ChatGPT\n",
    "#client is the openAI instance\n",
    "\n",
    "\n",
    "\n",
    "# passing the 2 files train.json,val.jsonl training and validation file the name of files is given above train and val.json\n",
    "#purpose is to fine tune\n",
    "training_file = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Creating a validation  file \n",
    "validation_file = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "\n",
    "# the traing file and valiation file has an id,  training file has the file given by open ai\n",
    "#and also the validation file,, these files are srtoreed in openAi databasse\n",
    "#training and vbalidation file is stored in chatgpt database of our instnace\n",
    "\n",
    "print(\"Training file id:\", training_file.id)\n",
    "print(\"Validation file id:\", validation_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e406951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-3sR401lywwo6s4g8B851cAXD', created_at=1708771251, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-0a5QYOkKHFH132BCdwAcQWDX', result_files=[], status='validating_files', trained_tokens=None, training_file='file-IDCSB0tz8UE9Roa4DNZHIo8O', validation_file='file-mNku25Ynikh0nmkDsWhZO05r')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_name = \"nutrimateModel\"\n",
    "\n",
    "#creating  a fine tune object \n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "\n",
    "# ususally we pass the trainign file in trainigfile and like wise for validation file\n",
    "# But for the context we created the files previosly and we just have to pass the id to make things easier\n",
    "#so it knows the file with the particular ID\n",
    "#so for the jobw e are doing we should give a suffix name  \n",
    "response\n",
    "\n",
    "#So response has the finetuned chatgpt instance , to fine tune a model it takes time so wait for a bit atleast an hour  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e6da764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-3sR401lywwo6s4g8B851cAXD', created_at=1708771251, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0613:personal:nutrimatemodel:8vk4PaWF', finished_at=1708772480, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-0a5QYOkKHFH132BCdwAcQWDX', result_files=['file-6pMf4xqAjcopwtGfXwbY4XlT'], status='succeeded', trained_tokens=28353, training_file='file-IDCSB0tz8UE9Roa4DNZHIo8O', validation_file='file-mNku25Ynikh0nmkDsWhZO05r')], object='list', has_more=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the above code shows that our model is fine tuned\n",
    "#this is our instance ID:  ftjob-3sR401lywwo6s4g8B851cAXD ,it tkaes a bit of time to fine tune our model\n",
    "\n",
    "\n",
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67812a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-3sR401lywwo6s4g8B851cAXD', created_at=1708771251, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0613:personal:nutrimatemodel:8vk4PaWF', finished_at=1708772480, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-0a5QYOkKHFH132BCdwAcQWDX', result_files=['file-6pMf4xqAjcopwtGfXwbY4XlT'], status='succeeded', trained_tokens=28353, training_file='file-IDCSB0tz8UE9Roa4DNZHIo8O', validation_file='file-mNku25Ynikh0nmkDsWhZO05r')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseModel = client.fine_tuning.jobs.retrieve(\"ftjob-3sR401lywwo6s4g8B851cAXD\")\n",
    "#we store our finetuned chatgpt instance in a a variable \n",
    "\n",
    "responseModel\n",
    "#Responsemoidel variable has all the data of our intance gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8220e7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned model id: ft:gpt-3.5-turbo-0613:personal:nutrimatemodel:8vk4PaWF\n"
     ]
    }
   ],
   "source": [
    "#printing the name of our gpt model given by openai thaTS STRORED IN RESOPNSE MODEL\n",
    "\n",
    "fine_tuned_model_id = responseModel.fine_tuned_model\n",
    "#We get the Id of the model we fine tuned, and we use  this model for new client responses, we dont need previos code as we fine tuned the model\n",
    "#so its not gptturbo anymore, its gpt turbo with our custom id denoting our custom gpt model\n",
    "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)\n",
    "\n",
    "#THIS IS OUR CUSTOM intance gpt , earlier it was gpt3.5 turbo now its our custom gpt trained witgh our instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ddacaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function thats going to call our custom gpt instance and getting its output message\n",
    "def predict(test_messages, fine_tuned_model_id):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0613:personal:nutrimatemodel:8vk4PaWF\", messages=test_messages, temperature=0, max_tokens=50\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70911278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b3b6f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rate\": \"bad\"}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSent = \"Role: Cocacola, User Description: I am a student having diabetese i am advised not to take foods that are very sugar saturated, i try my best to avoid such food items\"\n",
    "\n",
    "#the role below is goiven user and this has no mathcing  the role in our application , in OPEN ai the users are ,Agent,system , user\n",
    "#content is what we send the LLM from what the user has sent\n",
    "formatted_message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": testSent\n",
    "        }\n",
    "    ]\n",
    "\n",
    "predict(formatted_message,\"ft:gpt-3.5-turbo-0613:personal:nutrimatemodel:8vk4PaWF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "444365e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def format_test(row):\n",
    "\n",
    "    formatted_message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['prompt']\n",
    "        }\n",
    "    ]\n",
    "    return formatted_message\n",
    "\n",
    "\n",
    "def predict(test_messages, fine_tuned_model_id):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=50\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69dcb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_predictions(test_df, fine_tuned_model_id):\n",
    "\n",
    "    print(\"fine_tuned_model_id\",fine_tuned_model_id)\n",
    "    test_df['Prediction'] = None\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        test_message = format_test(row)\n",
    "        prediction_result = predict(test_message, fine_tuned_model_id)\n",
    "        test_df.at[index, 'Prediction'] = prediction_result\n",
    "\n",
    "    test_df.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46ddfe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_tuned_model_id ft:gpt-3.5-turbo-0613:personal:nutrimatemodel:8vk4PaWF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = pd.read_csv(\"nutrimate_rating_test.csv\")\n",
    "store_predictions(test_df, fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb85b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
